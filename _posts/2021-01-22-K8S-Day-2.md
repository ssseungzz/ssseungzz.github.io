---
title: 쿠버네티스 사용해 보기
categories:
  - Infra
tags:
  - k8s
toc: true
toc_label: "Contents"
toc_sticky: true
---

### K8S Day 2 - 쿠버네티스 사용해 보기

###### 도커와 다른 쿠버네티스만의 특징

* 모든 리소스는 오브젝트 형태로 관리
  * 쿠버네티스는 대부분의 리소스를 '오브젝트'라고 불리는 형태로 관리한다. 쿠버네티스에서는 컨테이너의 집합(pods), 컨테이너의 집합을 관리하는 컨트롤러(replica set), 사용자(service account), 노드(node)까지도 하나의 오브젝트로 사용할 수 있다.
  * `kubectl-api-resources`로 쿠버네티스에서 사용할 수 있는 오브젝트를 확인할 수 있다. 특정 오브젝트의 간단한 설명을 보고 싶다면 `kubectl explain`을 사용한다. 
* YAML 파일을 자주 사용
  * 쿠버네티스도 YAML 파일로 컨테이너 리소스를 정의하거나 삭제할 수 있다. 게다가 컨테이너뿐 아니라 거의 모든 리소스 오브젝트들에 사용될 수 있다. 컨테이너의 설정값, 비밀값 등도 모두 YAML 파일로 정의해 사용한다. 실제로 서비스를 배포할 때에도 `kubectl` 명령어가 아닌 여러 개의 YAML 파일을 정의해 쿠버네티스에 적용시키는 방식으로 동작한다.
  * 따라서 쿠버네티스를 잘 사용하는 것 == YAML 파일을 잘 작성하는 것!
* 여러 개의 컴포넌트로 구성
  * 쿠버네티스 노드는 마스터와 워커로 나뉘어 있다. 마스터 노드는 쿠버네티스가 제대로 동작할 수 있게 클러스터를 관리하는 역할을 담당하며, 워커 노드에는 애플리케이션 컨테이너가 생성된다.
  * 쿠버네티스는 도커를 포함한 매우 많은 컴포넌트들이 실행된다. 마스터 노드에는 API 서버(`kube-apiserver`), 컨트롤러 매니저(`kube-controller-manager`), 스케줄러(`kube-scheduler`), DNS 서버 등이 실행되며 모든 노드에서는 오버레이 네트워크 구성을 위해 프록시(`kube-proxy`)와 네트워크 플러그인 등이 실행된다. 
  * 이러한 컴포넌트들은 기본적으로 도커 컨테이너로서 실행된다.
  * 그리고 쿠버네티스 클러스터 구성을 위해 `kubelet`이라는 에이전트가 모든 노드에서 실행된다. 이는 컨테이너의 생성, 삭제뿐 아니라 마스터와 워커 노드 간의 통신 역할을 함께 담당하는 매우 중요한 에이전트이다.
  * 쿠버네티스는 컨테이너를 사용하기 위해 도커를 이용하는 방식으로 동작하므로 반드시 도커를 사용해야 하는 것은 아니며, OCI 표준을 구현한 CRI(Container Runtime Interface)를 갖추고 있다면 어떠한 컨테이너든 사용 가능하다.

###### 포드(Pods)에 대해 알아보기

* 쿠버네티스에서는 컨테이너 애플리케이션의 기본 단위를 포드라고 부른다. **포드는 1개 이상의 컨테이너로 구성된 컨테이너의 집합**이다. 도커 스웜 모드의 서비스와 비슷하다. 1개의 포드에는 1개 이상의 컨테이너가 존재할 수 있다.

* Nginx 컨테이너로 구성된 포드 생성

* ```yaml
  apiVersion: v1
  kind: Pod
  metadata:
    name: my-nginx-pod
  spec:
    containers:
    - name: my-nginx-container
      image: nginx:latest
    ports:
    - containerPort: 80
      protocol: TCP
  ```

  * `apiVersion`: YAML 파일에서 정의한 오브젝트의 API 버전을 나타낸다.

  * `kind`: 이 리소스의 종류를 나타낸다. 사용할 수 있는 리소스 오브젝트 종류는 `kubectl api-resources` 명령어의 `KIND` 항목에서 확인 가능하다.

  * `metadata`: 라벨, 주석 등과 같은 부가 정보를 입력한다.

  * `spec`: 리소스를 생성하기 위한 자세한 정보를 입력한다.

    > 참고: 포드의 YAML 파일에서는 `command`와 `args`도 사용될 수 있다. 이들은 컨테이너 내부에서 가장 먼저 실행될 프로세스를 지정한다. YAML 파일에서 `command`를 설정하면 도커 컨테이너의 entrypoint로, 포드에서 `args`를 설정하면 도커 컨테이너의 cmd로 치환된다.

* 작성한 YAML 파일은 `kubectl apply -f` 명령어로 쿠버네티스에 생성 가능하다.

* `kubectl get <object-name>`을 사용해서 특정 오브젝트의 목록을 확인할 수 있다.

* 위에서 작성한 포드는 외부에서 접근할 수 있도록 노출된 상태는 아니므로, 포드의 nginx 서버로 요청을 보내려면 포드 컨테이너의 내부 IP로 접근해야 한다. `kube describe` 명령어로 생성된 리소스의 자세한 정보를 얻을 수 있다. 

* ```bash
  > kubectl describe pods my-nginx-pod
  Name:         my-nginx-pod
  Namespace:    default
  Priority:     0
  Node:         gke-cluster-1-default-pool-ae74d636-34nw/10.128.0.3
  Start Time:   Fri, 22 Jan 2021 16:27:58 +0900
  Labels:       <none>
  Annotations:  kubernetes.io/limit-ranger: LimitRanger plugin set: cpu request for container my-nginx-container
  Status:       Running
  IP:           10.4.2.6
  IPs:
    IP:  10.4.2.6
  ```

  * 위에 적힌 IP는 클러스터 내부에서만 접근할 수 있다. 

* 쿠버네티스 외부 또는 내부에서 포드에 접근하려면 서비스라고 하는 쿠버네티스 오브젝트를 따로 생성해야 한다. 서비스를 생성하지 않고 IP만으로 nginx 포드에 접근해 보았다. `kubectl exec` 명령을 이용하면 쉘 명령어를 실행할 수 있다. `kubectl exec -it my-nginx-pod -- curl 10.4.2.6:80`라는 명령을 통해 HTTP 요청을 보내면 포드가 정상적으로 실행 중인 것을 알 수 있다. `kubectl logs`로 포드의 로그를 확인하면 nginx에 접근했던 기록을 확인할 수도 있다.

![](https://user-images.githubusercontent.com/55083845/105463810-f26cbf00-5cd3-11eb-9b23-b116c8bc3273.png)

* 쿠버네티스 오브젝트는 `kubectl delete -f` 명령어로 쉽게 삭제할 수 있다. 포드를 삭제하려면 포드 이름이나 YAML 파일 명을 적어 삭제 가능하다.
* 왜 도커 컨테이너가 아니라 포드 개념을 사용할까?
  * 컨테이너 런타임의 인터페이스 제공 등 여러 이유가 있지만 이유 중 하나는 여러 리눅스 네임스페이스(namespace)를 공유하는 컨테이너들을 추상화된 집합으로 사용하기 위해서이다.
  * 위에서 작성한 nginx 포드에 우분투 컨테이너를 추가해서 내부로 들어간 후에 컨테이너 내부에서 로컬호스트로 http 요청을 전송하면 nginx 서버의 응답이 도착하는 것을 확인할 수 있다. 
  * 이는 포드 내의 컨테이너들이 네트워크 네임스페이스 등과 같은 **리눅스 네임스페이스를 공유**해서 사용하기 때문이다.
    * Pause라는 이름의 컨테이너로부터 네트워크를 공유한다. pause 컨테이너는 네임스페이스를 공유하기 위해 포드별로 생성되는 컨테이너이며, 각 포드에 대해 자동으로 생성된다.
  * 실제 쿠버네티스 환경에서는 1개의 컨테이너로 구성된 포드를 사용하는 경우가 많다. 이는 *하나의 포드는 하나의 완전한 애플리케이션*이기 때문이다. 
    * 그러나 컨테이너가 실행되기 위해 부가적인 기능을 필요로 한다면 포드의 주 컨테이너와 함께 기능 확장을 위한 추가 컨테이너를 함께 포드에 포함시킬 수 있다. 이렇게 포드에 정의된 부가적인 컨테이너를 사이드카(sidecar) 컨테이너라고 부른다.

###### 레플리카셋(Replica Set)에 대해 알아보기

* 왜 사용할까?

  * YAML에 포드만 정의해 생성하게 되면 이 포드의 생애 주기는 어떻게 될까? `kubectl delete`로 포드를 삭제하면 그 포드의 컨테이너도 삭제된 뒤 쿠버네티스에서 사라지게 된다. 즉, YAML 파일에 포드만 정의해 사용할 경우 해당 포드는 쿠버네티스의 사용자에 의해 관리된다.
  * 실제로 사용자 요청을 처리해야 하는 경우 이러한 방식을 사용하기 어렵다. 스웜 모드에서처럼 여러 개의 동일한 컨테이너를 생성한 뒤 외부 요청이 각 컨테이너에 적절히 분배될 수 있어야 한다. 
  * 쿠버네티스의 기본 단위는 포드이므로 여러 개의 포드를 생성해서 요청을 포드에 분배하는 방식을 사용해야 할 것이다. 여러 개의 포드를 생성하는 가장 간단한 방법은 다른 이름을 가지는 여러 개의 포드를 직접 정의하는 방식이다. `---`를 구분자로 사용해서 YAML 파일에서 여러 개의 리소스를 정의할 수 있다. 하지만 이는 매우 비효율적이다. 직접 작성하는 게 번거로울 뿐더러 장애가 발생해 포드에 접근하지 못하게 되면 직접 포드를 삭제하고 다시 생성하지 않는 한 포드는 복구되지 않는다.

  * 따라서 레플리카셋이라는 쿠버네티스 오브젝트를 함께 사용한다.

* 레플리카셋의 역할

  * 정해진 수의 동일한 포드가 항상 실행되도록 관리한다.
  * 노드 장애 등의 이유로 포드를 사용할 수 없다면 다른 노드에서 포드를 다시 생성한다.

* 어떻게 사용할까?

  * Nginx 포드를 생성하는 레플리카셋을 만든다.

  ```yaml
  apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    name: replicaset-nginx
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: my-nginx-pods-label
    template:
      metadata:
        name: my-nginx-pod
        labels:
          app: my-nginx-pods-label
      spec:
        containers:
        - name: nginx
          image: nginx:latest
          ports:
          - containerPort: 80
  ```

  * 리소스의 고유한 이름은 포드뿐안 아니라 모든 쿠버네티스 오브젝트에서 설정할 수 있다. 레플리카셋의 이름은 `metadata.name`에서 설정했다.
    * `spec.replicas`: 동일한 포드를 몇 개 유지시킬 것인지 설정한다.
    * `spec.template`: 포드를 생성할 때 사용할 템플릿을 정의한다. 포드를 사용했던 내용을 동일하게 레플리카셋에도 정의함으로써 어떠한 포드를 어떻게 생성할지 명시한다. 보통 **포드 스펙** 또는 **포드 템플릿**이라고 불린다.
  * 포드 생성과 동일하게 `kubectl apply -f` 명령어로 YAML 파일을 읽어서 생성 가능하다.

  ![](https://user-images.githubusercontent.com/55083845/105655974-9046d080-5f04-11eb-9f66-3ef12477372e.png)

  * 이번에는 포드의 개수를 `spec.replicas`의 숫자를 바꾸어 변경한다. 새로운 파일을 만들어서 `replicas`의 수만 4로 변경한 뒤 `kubectl apply -f`를 사용하면 기존의 리소스를 수정한 것이므로 `replicaset.apps/replicaset-nginx configured`라는 문구가 출력된다.
  * 포드와 마찬가지로 레플리카셋도 `kubectl delete`를 통해 가능하다.

* 레플리카셋은 어떻게 동작할까?
  * 레플리카셋은 포드와 느슨한 연결을 유지한다. 이는 **라벨 셀렉터**를 이용해 이루어진다. 포드를 생성할 때 `metadata`로 설정할 수 있는 것에는 리소스 이름뿐 아니라 애노테이션, 라벨 등이 있다. 라벨은 쿠버네티스 리소스의 부가적인 정보 표현뿐 아니라 서로 다른 오브젝트가 서로를 찾아야 할 때 사용되기도 한다. 레플리카셋은 `spec.selector.matchLabel`에 정의된 라벨을 통해 생성해야 하는 포드를 찾는다. 
  * 정해진 라벨을 가지는 포드의 개수가 `replicas` 항목에 정의된 수와 일치하지 않으면 템플릿 항목의 내용으로 코드를 생성한다.
  * 즉, 라벨을 통해 레플리카셋은 **일정한 개수의 포드를 유지**한다.

###### 디플로이먼트(Deployment)로 레플리카셋과 포드의 배포 관리하기

* 실제 운영 환경에서는 레플리카셋과 포드의 정보를 정의하는 디플로이먼트라는 이름의 오브젝트를 YAML 파일에 정의해 사용한다. 레클리카셋의 상위 오브젝트이기 때문에 디플로이먼트를 생성하면 해당 디플로이먼트에 대응하는 래플리카셋도 함께 생성된다.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-nginx
  template:
    metadata:
      name: my-nginx-pod
      labels:
        app: my-nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.10
        ports:
        - containerPort: 80
```

* 위 YAML 파일로 디플로이먼트를 생성하면 디플로이먼트, 레플리카셋, 포드가 생성된 것을 확인할 수 있다. 디플로이먼트를 생성함으로써 레플리카셋이 생성되고 레플리카셋이 포드를 생성한다. 따라서 디플로이먼트를 삭제한 레플리카셋과 포드도 삭제된다.

![](https://user-images.githubusercontent.com/55083845/105666148-f8ed7780-5f1b-11eb-9362-39fb593f96f5.png)

* 왜 디플로이먼트를 사용할까?

  * 핵심적인 이유 중 하나는 애플리케이션의 업데이트와 배포를 더욱 편하게 만들기 위해서이다. 디플로이먼트는 컨테이너 애플리케이션을 배포하고 관리하는 역할을 담당한다. 예를 들어 애플리케이션을 업데이트할 때 레플리카셋의 변경 사항을 저장하는 리비전을 남겨 롤백을 가능하게 해 주고, 무중단 서비스를 위해 포드의 롤링 업데이트의 전략을 지정할 수도 있다. 
  * 포드의 이미지 버전을 `kubectl set image deployment my-nginx-deployment nginx=nginx:1.11 --record`로 변경해 보자. 파일을 직접 변경하고 `kubectl apply -f` 명령어를 적용해도 동일하게 변경된다.

  ![](https://user-images.githubusercontent.com/55083845/105666507-c1cb9600-5f1c-11eb-85df-f508cb6fbac5.png)
  * 해시값으로 보았을 때 처음 생성되었던 레플리카셋과 업데이트를 통해 새로 생성된 레플리카셋이 있음을 알 수 있다. 이전의 레플리카셋은 포드를 생성하고 있지는 않지만 삭제되지는 않았다. 디플로이먼트는 포드의 정보가 변경되어 업데이트가 발생했을 때 이전의 정보를 리비전으로 보존한다. `kubectl rollout history deployment <deployment-name>`으로 자세한 정보를 확인할 수 있다.
  * `--record=true` 옵션으로 디플로이먼트를 변경하면 변경 사항을 디플로이먼트에 기록함으로써 해당 버전의 레플리카셋을 보존할 수 있다.
  * `kubectl rollout undo deployment <deployment-name> --to-revision=`으로 이전 버전의 레플리카셋으로 롤백할 수 있다. `--to-revision`에는 되돌리려는 리비전의 번호를 입력한다. 리비전의 번호는 `kubectl rollout history deployment <deployment-name>`에서 확인 가능하다.

###### 서비스(Service)에 대해 알아보기

* 디플로이먼트를 통해 생성된 포드에 어떻게 접근할 수 있을까?	

  * 포드의 IP는 영속적이지 않다. 여러 개의 디플로이먼트를 하나의 완벽한 애플리케이션으로 연동하려면 포드 IP가 아닌 서로를 발견할 수 있는 다른 방법이 필요하다.
  * 쿠버네티스는 포드에 접근하도록 하는 방법이 도커와 약간 다르다. 쿠버네티스는 디플로이먼트를 생성할 때 포드를 외부로 노출하지 않고, 디플로이먼트의 YAML 파일에는 단지 포드의 애플리케이션이 사용할 내부 포트만 정의한다.
  * 이 포트를 외부로 노출해 사용자들이 접근하거나 다른 디플로이먼트의 포드들이 내부적으로 접근하려면 **서비스**라고 부르는 별도의 쿠버네티스 오브젝트를 생성해야 한다.
  * 서비스는 포드에 접근하기 위한 규칙을 정의한다.

* 서비스의 핵심 기능은 다음과 같다.

  * 여러 개의 포드에 쉽게 접근할 수 있도록 고유한 도메인 이름 부여
  * 여러 개의 포드에 접근할 때 요청을 분산하는 로드 밸런서 기능 수행
  * 클라우드 플랫폼의 로드 밸런서, 클러스터 노드의 포트 등을 통해 포드를 외부로 노출

* 서비스의 종류

  * 서비스와 포드를 연결해 보자. 먼저 디플로이먼트를 생성한다.

  ```yaml
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: hostname-deployment
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: webserver
    template:
      metadata:
        name: my-webserver
        labels:
          app: webserver
      spec:
        containers:
        - name: my-webserver
          image: alicek106/rr-test:echo-hostname
          ports:
          - containerPort: 80
  ```

  * 포드에 접근할 수 있는 규칙을 정의하는 서비스 리소스를 생성한다. 쿠버네티스의 서비스는 포드에 어떻게 접근할 것이냐에 따라 종류가 여러 개로 세분화되어 있으므로 **목적에 맞는 적절한 서비스의 종류를 선택**해야 한다.
  * 주로 사용하는 서비스 타입에는 크게 세 가지가 있다.
    * ClusterIP 타입: 쿠버네티스 내부에서만 포드들에 접근할 때 사용한다. 포드를 외부로 노출하기 않기 때문에 쿠버네티스 클러스터 내부에서만 사용되는 포드에 적합하다.
    * NodePort 타입: 포드에 접근할 수 있는 포트를 클러스터의 모든 노드에 동일하게 개방한다. 따라서 외부에서 포드에 접근할 수 있다. 접근할 수 있는 포트는 랜덤으로 정해지지만, 특정 포트로 접근하도록 설정할 수 있다.
    * LoadBalancer 타입: 클라우드 플랫폼에서 제공하는 로드 밸런스를 동적으로 프로비저닝해 포드에 연결한다. 외부에서 포드에 접근할 수 있다. 그렇지만 일반적으로 AWS, GCP와 같은 클라우드 플랫폼에서만 사용할 수 있다.

* ClusterIP 타입

  * YAML 파일을 작성해 보자.

  ```yaml
  apiVersion: v1
  kind: Service
  metadata:
    name:hostname-svc-clusterip
  spec:
    ports:
    - name: web-port
      port: 8080
      targetPort: 80
    selector:
      app: webserver
    type: ClusterIP
  ```

  * `spec.selector`: 이 서비스에서 어떠한 라벨을 가지는 포드에 접근할 수 있게 만들 것인지 결정한다. 
  * `spec.ports.port`: 생성된 서비스는 쿠버네티스 내부에서만 사용할 수 있는 고유한 IP를 할당받는다. port 항목에는 서비스의 IP에 접근할 때 사용할 포트를 설정한다.
  * `spec.ports.targetPort`: `selector` 항목에서 정의한 라벨에 의해 접근 대상이 된 포드들이 내부적으로 사용하고 있는 포트를 입력한다. `deployment-hostname.yaml` 파일의 `containerPort` 항목에서 포드가 사용할 포트를 80으로 선언했기 때문에 동일하게 80으로 설정했다.
  * `spec.type`: 이 서비스가 어떤 타입인지 나타낸다.
  * 서비스를 생성한다. 다른 리소스들과 마찬가지로 `kubectl apply -f` 사용한다.
  * 서비스의 목록을 확인하고 `CLUSTER-IP` 항목의 IP와 `PORT(S)` 항목의 포트를 통해 요청을 보낸다.

  ![](https://user-images.githubusercontent.com/55083845/105676510-f5fb8280-5f2d-11eb-93a4-d4e382aa2f1e.png)

  * 서비스의 IP와 포트를 통해 포드에 접근할 수 있다. 여러 개의 포드에 자동으로 요청이 분산되는 것도 확인할 수 있다.

  * IP뿐만 아니라 서비스 이름 자체로도 접근할 수 있다. 쿠버네티스는 애플리케이션이 서비스나 포드를 쉽게 찾을 수 있도록 내부 DNS를 구동하고 있으며, 포드들은 자동으로 DNS를 사용하도록 설정되어 있기 대문이다.

  * 이 과정을 정리하면 아래와 같다. ClusterIP 타입의 서비스는 외부에서 접근할 수 없다는 점에 유의해야 한다.

    > 1. 특정 라벨을 가지는 포드를 서비스와 연결하기 위해 서비스의 YAML 파일에 `selector` 항목을 정의한다.
    > 2. 포드에 접근할 때 사용하는 포트(포드에 설정된 `containerPort`)를 YAML 파일의 `targetPort` 항목에 정의한다.
    > 3. 서비스를 생성할 때 YAML 파일의 `port` 항목에 8080을 명시해 서비스의 ClusterIP와 8080 포트로 접근할 수 있게 설정한다.
    > 4. `kubectl apply -f` 명령어로 ClusterIP 타입의 서비스가 생성되면 서비스는 쿠버네티스 클러스터 내부에서만 사용할 수 있는 고유한 내부 IP를 할당받는다.
    > 5. 쿠버네티스 클러스터에서 서비스의 내부 IP 또는 서비스 이름으로 포드에 접근할 수 있다.

* NodePort 타입

  * 클러스터 외부에서도 접근할 수 있지만 모든 노드의 특정 포트를 개방해 서비스에 접근하는 방식이다. 
  * YAML 파일을 작성해 보자.

  ```yaml
  apiVersion: v1
  kind: Service
  metadata:
    name: hostname-svc-nodeport
  spec:
    ports:
    - name: web-port
      port: 8080
      targetPort: 80
    selector:
      app: webserver
    type: NodePort
  ```

  * 모든 노드에서 동일하게 접근할 수 있는 포트가 생성된다. 모든 노드에 내부 IP 또는 외부 IP를 통해 30289 포트로 접근하면 동일한 서비스에 연결할 수 있다.

  ![](https://user-images.githubusercontent.com/55083845/105680386-006c4b00-5f33-11eb-8927-81a3b816c1f7.png)

  * 단, GKE에서 쿠버네티스를 사용하는 경우 각 노드의 랜덤한 포트에 접근하기 위해 별도로 방화벽 설정을 추가해야 한다. AWS에서도 마찬가지로 Security Group에 별도의 인바운드 규칙을 추가해야 한다.

  ```bash
  gcloud compute firewall-rules create temp-nodeport-svc --allow=tcp:30289 # 규칙 생성
  gcloud compute firewall-rules delete temp-nodeport-svc # 규칙 삭제
  ```

  * NodePort 타입의 서비스는 ClusterIP 기능을 포함하므로 자동으로 ClusterIP의 기능을 사용할 수 있다. 따라서 쿠버네티스 클러스터에서 서비스의 내부 IP와 DNS를 사용해 접근할 수 있다.
  * 실제 운영 환경에서는 SSL 인증서 적용, 라우팅 등과 같은 복잡한 설정을 서비스의 적용하기가 어려우므로 NodePort 서비스 그 자체를 통해 서비스를 외부로 제공하기보다는 **인그레스(Ingress)**라고 불리는 쿠버네티스의 오브젝트에서 간접적으로 사용되는 경우가 많다.

* LoadBalancer 타입

  * 서비스 생성과 동시에 로드 밸런서르 ㄹ새롭게 생성해 포드와 연결한다. 클라우드 플랫폼으로부터 도메인 이름과 IP를 할당받기 때문에 포드에 접근하기가 더욱 쉬워진다.
  * 단, 이 타입의 서비스는 로드 밸런서를 동적으로 생성하는 기능을 제공하는 환경에서만 사용할 수 있다.

  ```yaml
  apiVersion: v1
  kind: Service
  metadata:
    name: hostname-svc-lb
  spec:
    ports:
    - name: web-port
      port: 80
      targetPort: 80
    selector:
      app: webserver
    type: LoadBalancer
  ```

  * 생성한 뒤 목록을 확인해 보면 아래와 같이 `EXTERNAL-IP` 항목에 IP사 할당된 것을 볼 수 있다. 이 주소는 클라우드 플랫폼으로부터 자동으로 할당된 것이고, 이 주소와 YAML 파일의 `ports.port` 항목에 작성한 포트 번호를 통해 포드에 접근할 수 있다.

  ![](https://user-images.githubusercontent.com/55083845/105686199-52fd3580-5f3a-11eb-9b23-78f335add8d0.png)

  * 31811은 각 노드에서 동일하게 접근할 수 있는 포트 번호를 의미한다. 이 포트 번호를 이용해 각 노드의 IP로 접근해 보면 로드 밸런서와 똑같이 포드에 접근할 수 있다. 

  * 왜 이 포트가 개방되었을까? 이는 LoadBalancer 타입의 서비스가 요청을 포드로 전송하는 원리에 있다.

    > 1. LoadBalancer 타입의 서비스가 생성됨과 동시에 모든 워커 노드는 포드에 접근할 수 있는 랜덤한 포트를 개방한다.
    > 2. 클라우드 플랫폼에서 생성된 로드 밸런서로 요청이 들어오면 이 요청은 쿠버네티스 워커 노드 중 하나로 전달되며, 이때 사용되는 포트가 1번에서 개방된 포트이다.
    > 3. 워커 노드로 전달된 요청은 포드 중 하나로 전달되어 처리된다.

  * 특별한 설정을 하지 않으면 클라우드 플랫폼의 기본적인 설정에 따르는 로드 밸런서를 사용하게 되지만, 필요에 따라 다른 종류의 로드 밸런서를 생성할 수 있다. 예를 들어 AWS를 사용하고 있다면 YAML 파일의 `metedata.annotation` 항목에 `service.beta.kubernetes.io/aws-load-balancer-type: "nlb"`를 통해 네트워크 로드 밸런서를 사용할 수 있다.

    > 쿠버네티스에서 주석은 리소스의 추가적인 정보를 나타내기 위한 키-값으로 이루어져 있다. 그렇지만 리소스의 종류에 따라 특정 용도로 사용할 수 있게 쿠버네티스에서 미리 정의한 몇 가지 주석이 있다.

  * LoadBalancer 타입의 서비스를 사용하면 외부로부터 들어온 요청은 각 노드 중 하나로 보내지며, 그 노드에서 다시 포드 중 하나로 전달된다. 이는 NodePort 타입도 마찬가지이다. 그런데 특정 노드로 들어온 요청을 거기에서 처리할 수 있음에도 불구하고 굳이 또 다른 노드로 보내는 것은 비효율적일 수 있다. 
    
    * 요청 전달 매커니즘은 서비스의 속성 중 `externalTrafficPolicy` 항목에 정의돼 있다. 기본 설정인 Cluster는 클러스터의 모든 노드에 랜덤한 포트를 개방하는 방식이다. 이를 `Local`로 설정하면 포드가 생성된 노드에서만 포드로 접근할 수 있으며, 로컬 노드에 위치한 포드 중 하나로 요청이 전달된다.

  ```yaml
  apiVersion: v1
  kind: Service
    metadata:
      name: hostname-svc-lb-local
    spec:
      externalTrafficPolicy: Local
      ports:
        - name: web-port
          port: 80
          targetPort: 80
    selector:
      app: webserver
    type: LoadBalancer
  ```

  * `externalTraffiPolicy`를 `Local`로 설정하면 포드가 위치한 랜덤한 포트를 개방한다. 로드 밸런서는 포드가 위치한 노드로만 요청을 전달하며, 해당 노드 내의 포드에서만 요청이 분산되므로 네트워크 홉이 한 단계 적고 클라이언트의 IP를 포드의 소스코드 내에서 확인 가능하다.
  * 하지만 각 노드에 포드가 고르지 않게 스케줄링 됐을 때 요청이 고르게 분산되지 않을 수 있다.

* ExternalName 타입

  * 쿠버네티스를 외부 시스템과 연동할 때 사용할 수 있다. 이 타입을 사용해 서비스를 생성하면 서비스가 외부 도메인을 가리키도록 설정할 수 있다. 예를 들어, 아래의 설정은 쿠버네티스 내부의 포드들이 `externalname-svc`라는 이름으로 요청을 보낼 경우 쿠버네티스의 DNS는 `my.sample.com`으로 접근할 수 있도록 한다. 

  ```yaml
  apiVersion: v1
  kind: Service
  metadata:
    name: external-svc
  spec:
    type: ExternalName
    externalName: my.sample.com
  ```




##### References

[시작하세요! 도커/쿠버네티스 (개정판)](https://wikibook.co.kr/docker-kube-rev/)

